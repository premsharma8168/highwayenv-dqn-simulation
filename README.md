# ğŸš— Simulation-Oriented Debugging Agent for Autonomous Car Overtaking

An **AI-powered Reinforcement Learning project** that trains an autonomous vehicle agent to perform **safe and intelligent overtaking maneuvers** on highways.
This system leverages **Simulation-Oriented Debugging** to monitor, analyze, and optimize overtaking decisions using **Deep Q-Networks (DQN)** with **PyTorch** and **Stable Baselines3**.

---

## ğŸ§© Features

* ğŸ§  **Simulation-Oriented Debugging** â€” continuously evaluates and adjusts overtaking logic during simulation.
* âš™ï¸ **Custom Reward Function** â€” promotes smooth, safe, and realistic driving behavior.
* ğŸš€ **GPU-Accelerated Training** â€” powered by CUDA for efficient learning.
* ğŸ® **Real-Time Visualization** â€” displays live simulation with Matplotlib.
* ğŸ’¾ **Auto Model Loader** â€” detects and loads the latest trained model `.zip` file automatically.
* ğŸ§± **Modular Design** â€” separate scripts for training and demo execution.

---

## ğŸ—‚ï¸ Project Structure

```
ğŸ“¦ Simulation-Oriented-Debugging-Agent/
â”‚
â”œâ”€â”€ main.py                  # Trains the DQN agent (safe overtaking logic)
â”œâ”€â”€ demo_final_autoload.py   # Demonstrates the trained model live
â”œâ”€â”€ rl_overtake_safe_realistic_v2.zip   # Generated model after training
â”œâ”€â”€ output.jpg               # Screenshot of simulation output
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

### Prerequisites

* Python **3.9+**
* CUDA-compatible GPU (optional but recommended)



---

## ğŸš€ How to Run

### ğŸ§  Train the Model

```bash
python main.py
```

This will:

* Configure the **highway simulation** (`highway-v0`)
* Train a **Deep Q-Network (DQN)** for 150,000 timesteps
* Save the trained model as `rl_overtake_safe_realistic_v2.zip`

---

### ğŸ¬ Run the Demo

```bash
python demo_final_autoload.py
```

The demo script will:

* Auto-detect the latest model `.zip` file
* Load the model on GPU
* Render a **live simulation** of overtaking behavior
* Display real-time reward updates

Press **Ctrl + C** anytime to stop the simulation safely.

---

## ğŸ§  Technical Overview

| Component                  | Description                                                     |
| -------------------------- | --------------------------------------------------------------- |
| **Algorithm**              | DQN (Deep Q-Network)                                            |
| **Framework**              | Stable Baselines3                                               |
| **Simulation Environment** | highway-env (`highway-v0`)                                      |
| **Observation Type**       | Kinematics                                                      |
| **Reward Strategy**        | Safety, smooth speed, lane change efficiency, collision penalty |

---

## ğŸ“Š Outputs

Below is a sample output of the simulation after training:

<p align="center">
  <img src="output.jpg" alt="Simulation Output" width="700"/>
</p>

* ğŸ§© **Trained Model:** `rl_overtake_safe_realistic_v2.zip`
* ğŸ¥ **Live Simulation:** Real-time vehicle behavior visualization
* ğŸ–¥ï¸ **Console Logs:** Step-by-step rewards and total episode summary

---

## ğŸ‘¨â€ğŸ’» Author

**Prem Narayan Sharma**
B.Tech CSE (III Year â€“ V Semester)
Department of Computer Engineering and Applications
GLA University, Mathura
ğŸ“§ [premnsharma2005@outlook.com](mailto:premnsharma2005@outlook.com)

---

## ğŸ§¾ Notes

* Modify environment parameters in `make_env()` inside `main.py` for different highway conditions.
* You can skip training by using the existing pre-trained `.zip` model.
* Compatible with both **Windows** and **Linux**.

---

> ğŸ’¡ *This project demonstrates the fusion of Reinforcement Learning and Simulation-Based Debugging for safe autonomous driving systems â€” focusing on efficient, explainable, and collision-free overtaking.*
